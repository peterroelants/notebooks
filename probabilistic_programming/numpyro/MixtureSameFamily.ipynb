{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "866a80fb-3de9-4588-a0b6-9736df47a169",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from jax import lax\n",
    "\n",
    "import numpyro\n",
    "from numpyro.infer import MCMC, NUTS, Predictive\n",
    "import numpyro.distributions as dist\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm  # Colormaps\n",
    "import seaborn as sns\n",
    "import arviz as az\n",
    "\n",
    "from tqdm import tqdm_notebook as tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a21ef3e2-98d1-4dbd-b22c-0e25f9c3df74",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style('darkgrid')\n",
    "az.rcParams['stats.hdi_prob'] = 0.90\n",
    "az.style.use(\"arviz-darkgrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee4a1244-e22f-4a1f-bfae-6c7ad95cf901",
   "metadata": {},
   "outputs": [],
   "source": [
    "numpyro.set_platform('cpu')\n",
    "numpyro.set_host_device_count(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "536e2667-d787-4e87-a58d-2c46c2fd2386",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "rng_key = jax.random.PRNGKey(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54ebcf55-3602-4b28-b03d-aec7de281d67",
   "metadata": {},
   "source": [
    "## Mixture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75cf4e80-9ece-4474-af7b-54c19221dc58",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpyro.distributions import Distribution, Categorical\n",
    "from numpyro.distributions.util import (\n",
    "    validate_sample,\n",
    "    is_prng_key\n",
    ")\n",
    "\n",
    "\n",
    "class MixtureSameFamily(Distribution):\n",
    "    \"\"\"\n",
    "    Marginalized Mixture\n",
    "    \n",
    "    :param mixing_probabilities: The mixing probabilities between the different distributions of the mixture.\n",
    "        Shape = (*batch_shape, nb_of_mixtures)\n",
    "    :param component_distribution: Component distribution vectorized \n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        mixing_probabilities,\n",
    "        component_distribution,\n",
    "        validate_args=None\n",
    "    ):\n",
    "        print(\"\\nMixtureSameFamily.__init__\")\n",
    "        self._mixture_size = mixing_probabilities.shape[-1]\n",
    "        print(\"\\t_mixture_size: \", self._mixture_size)\n",
    "        self._categorical = dist.Categorical(mixing_probabilities)\n",
    "        print(\"\\tself._categorical.shape(): \", self._categorical.shape())\n",
    "        print(\"\\tself._categorical.batch_shape: \", self._categorical.batch_shape)\n",
    "        print(\"\\tself._categorical.event_shape: \", self._categorical.event_shape)\n",
    "        print(\"\\tself._categorical.event_dim: \", self._categorical.event_dim)\n",
    "        self._component_distribution = component_distribution\n",
    "        print(\"\\tself._component_distribution.shape(): \", self._component_distribution.shape())\n",
    "        print(\"\\tself._component_distribution.batch_shape: \", self._component_distribution.batch_shape)\n",
    "        print(\"\\tself._component_distribution.event_shape: \", self._component_distribution.event_shape)\n",
    "        print(\"\\tself._component_distribution.event_dim: \", self._component_distribution.event_dim)\n",
    "        if not isinstance(self._component_distribution, Distribution):\n",
    "            raise ValueError(\n",
    "                \"The component distribution need to be a numpyro.distributions.Distribution. \"\n",
    "                f\"However, it is of type {type(self._component_distribution)}\"\n",
    "            )\n",
    "        expected_component_batch_shape = self._categorical.batch_shape + (self.mixture_size,)\n",
    "        assert self._component_distribution.batch_shape == expected_component_batch_shape, (\n",
    "            f\"Component distribution batch shape does not correspond to expected shape according to the \"\n",
    "            f\"mixing probabilities shape {self._component_distribution.batch_shape} != {expected_component_batch_shape}\"\n",
    "        )\n",
    "        batch_shape = mixing_probabilities.shape[:-1]\n",
    "        print(\"\\tbatch_shape: \", batch_shape)\n",
    "        event_shape = component_distribution.event_shape\n",
    "        print(\"\\tevent_shape: \", event_shape)\n",
    "        super().__init__(batch_shape=batch_shape, event_shape=event_shape, validate_args=validate_args)\n",
    "        \n",
    "    @property\n",
    "    def mixture_size(self):\n",
    "        \"\"\"\n",
    "        Returns the number of distributions in the mixture\n",
    "\n",
    "        :return: number of mixtures.\n",
    "        :rtype: int\n",
    "        \"\"\"\n",
    "        return self._mixture_size\n",
    "\n",
    "\n",
    "    def sample(self, key, sample_shape=()):\n",
    "        \"\"\"\n",
    "        Returns a sample from the mixture distribution having shape given by\n",
    "        `sample_shape + batch_shape + event_shape`. Note that when `sample_shape` is non-empty,\n",
    "        leading dimensions (of size `sample_shape`) of the returned sample will\n",
    "        be filled with iid draws from the distribution instance.\n",
    "\n",
    "        :param jax.random.PRNGKey key: the rng_key key to be used for the distribution.\n",
    "        :param tuple sample_shape: the sample shape for the distribution.\n",
    "        :return: an array of shape `sample_shape + batch_shape + event_shape`\n",
    "        :rtype: numpy.ndarray\n",
    "        \"\"\"\n",
    "        print(f\"MixtureSameFamily.sample(sample_shape={sample_shape})\")\n",
    "        assert is_prng_key(key)\n",
    "        key_comp, key_ind = jax.random.split(key)\n",
    "#         samples:  (100, 7, 3, 2)\n",
    "        # Samples from component distribution will have shape (*sample_shape, *batch_shape, *event_shape)\n",
    "        samples = self._component_distribution.sample(key_comp, sample_shape)\n",
    "        assert samples.shape == (*sample_shape, *self.batch_shape, self.mixture_size, *self.event_shape)\n",
    "        print(\"\\tsamples: \", samples.shape)\n",
    "        # Sample selection indices from the categorical (shape will be sample_shape)\n",
    "        ind = self._categorical.sample(key_ind, sample_shape)\n",
    "#         assert ind.shape == sample_shape\n",
    "        print(\"\\tind: \", ind.shape)\n",
    "#         _x = lax.broadcast_shapes(jnp.shape(ind), jnp.shape(samples))\n",
    "#         print(\"_x: \", _x)\n",
    "#         ind_t = ind[..., None]\n",
    "#         print(\"\\tind_t: \", ind_t.shape)\n",
    "        # Account for default event dimension and end of range (+2 total)\n",
    "#         axis_expand = tuple(range(-1, -(self.event_dim+2), -1))\n",
    "#         print(\"\\taxis_expand: \", axis_expand)\n",
    "#         ind_expanded = jnp.expand_dims(ind, axis=axis_expand)\n",
    "        n_expand = self.event_dim + 1\n",
    "        ind_expanded = ind.reshape(ind.shape + (1,)*n_expand)\n",
    "#         _r = jax.lax.index_take(samples, idxs=ind, axes=(0,))\n",
    "#         print(\"_r: \", _r.shape)\n",
    "        print(\"\\tind_expanded: \", ind_expanded.shape)\n",
    "#         assert np.allclose(ind_expanded, ind_t)\n",
    "        axis_to_select = -(self.event_dim+1)\n",
    "        print(\"\\taxis_to_select: \", axis_to_select)\n",
    "        samples_selected = jnp.take_along_axis(samples, indices=ind_expanded, axis=axis_to_select)\n",
    "        print(\"\\tsamples_selected: \", samples_selected.shape)\n",
    "        final_samples = jnp.squeeze(samples_selected, axis=axis_to_select)\n",
    "        assert final_samples.shape == (*sample_shape, *self.batch_shape, *self.event_shape)\n",
    "        return final_samples\n",
    "\n",
    "    @validate_sample\n",
    "    def log_prob(self, value):\n",
    "        \"\"\"\n",
    "        Evaluates the log probability density for a batch of samples given by\n",
    "        `value`.\n",
    "\n",
    "        :param value: A batch of samples from the distribution.\n",
    "        :return: an array with shape `value.shape[:-self.event_shape]`\n",
    "        :rtype: numpy.ndarray\n",
    "        \n",
    "        \n",
    "        \n",
    "        Return shape (*value.shape[:-self.event_shape])\n",
    "        \"\"\"\n",
    "        print(f\"MixtureSameFamily.log_prob(value={value.shape})\")\n",
    "#         value_reshaped = value[..., None]\n",
    "        nb_value_dims = len(value.shape) - self.event_dim  # Without event dim\n",
    "        print(\"\\tnb_value_dims: \", nb_value_dims)\n",
    "        if len(self.batch_shape) > 0:\n",
    "            batch_shape_size = len(self.batch_shape)\n",
    "            print(\"\\tbatch_shape_size: \", batch_shape_size)\n",
    "            assert value.shape[-batch_shape_size:] == self.batch_shape\n",
    "        prob_dim = (1,)\n",
    "        reshape = value.shape[:nb_value_dims] + prob_dim + self.event_shape\n",
    "        print(\"\\treshape: \", reshape)  \n",
    "        value_reshaped = value.reshape(reshape)\n",
    "        print(\"\\tvalue_reshaped: \", value_reshaped.shape)\n",
    "        probs_mixture = self._component_distribution.log_prob(value_reshaped)\n",
    "        print(\"\\tprobs_mixture: \", probs_mixture.shape)\n",
    "        print(\"\\tself._categorical.logits: \", self._categorical.logits.shape)\n",
    "        sum_log_probs = self._categorical.logits + probs_mixture\n",
    "        print(\"\\tsum_log_probs: \", sum_log_probs.shape)\n",
    "        lse = jax.nn.logsumexp(sum_log_probs, axis=-1)  # TODO: double check if these really are logprobs\n",
    "        print(\"\\tlse: \", lse.shape)\n",
    "        expected_shape = value.shape[:nb_value_dims]\n",
    "        print(\"\\texpected_shape: \", expected_shape)\n",
    "        assert lse.shape == expected_shape\n",
    "        return lse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caf23248-9fa7-4f3d-9c72-4b722fff370b",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 3\n",
    "mixing_probabilities = jnp.ones(k) / k\n",
    "print(\"mixing_probabilities: \", mixing_probabilities.shape)\n",
    "loc = jnp.zeros(k)\n",
    "print(\"loc: \", loc.shape)\n",
    "scale = jnp.ones(k)\n",
    "print(\"scale: \", scale.shape)\n",
    "print('')\n",
    "normal= dist.Normal(loc=loc, scale=scale)\n",
    "print(\"normal.shape(): \", normal.shape())\n",
    "print(\"normal.batch_shape: \", normal.batch_shape)\n",
    "print(\"normal.event_shape: \", normal.event_shape)\n",
    "print(\"normal.event_dim: \", normal.event_dim)\n",
    "print('')\n",
    "mixed = MixtureSameFamily(mixing_probabilities=mixing_probabilities, component_distribution=normal)\n",
    "print(\"mixed.shape(): \", mixed.shape())\n",
    "print(\"mixed.batch_shape: \", mixed.batch_shape)\n",
    "print(\"mixed.event_shape: \", mixed.event_shape)\n",
    "print(\"mixed.event_dim: \", mixed.event_dim)\n",
    "print(\"mixed.mixture_size: \", mixed.mixture_size)\n",
    "print('')\n",
    "samples = mixed.sample(rng_key, (100,))\n",
    "print('samples: ', samples.shape)\n",
    "print('')\n",
    "lp = mixed.log_prob(samples)\n",
    "print('lp: ', lp.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aee4b5a-fc2f-4de9-8fbc-baf9211f674d",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 3\n",
    "mixing_probabilities = jnp.ones(k) / k\n",
    "print(\"mixing_probabilities: \", mixing_probabilities.shape)\n",
    "loc = jnp.zeros(k)\n",
    "print(\"loc: \", loc.shape)\n",
    "scale = jnp.ones(k)\n",
    "print(\"scale: \", scale.shape)\n",
    "print('')\n",
    "normal= dist.Normal(loc=loc, scale=scale)\n",
    "print(\"normal.shape(): \", normal.shape())\n",
    "print(\"normal.batch_shape: \", normal.batch_shape)\n",
    "print(\"normal.event_shape: \", normal.event_shape)\n",
    "print(\"normal.event_dim: \", normal.event_dim)\n",
    "print('')\n",
    "mixed = MixtureSameFamily(mixing_probabilities=mixing_probabilities, component_distribution=normal)\n",
    "print(\"mixed.shape(): \", mixed.shape())\n",
    "print(\"mixed.batch_shape: \", mixed.batch_shape)\n",
    "print(\"mixed.event_shape: \", mixed.event_shape)\n",
    "print(\"mixed.event_dim: \", mixed.event_dim)\n",
    "print('')\n",
    "samples = mixed.sample(rng_key, (100, 7))\n",
    "print('samples: ', samples.shape)\n",
    "print('')\n",
    "lp = mixed.log_prob(samples)\n",
    "print('lp: ', lp.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c97ae63-2dd3-497c-a696-2eacab2da3b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 3\n",
    "s = 4\n",
    "mixing_probabilities = jnp.vstack([jnp.ones(k) / k for _ in range(s)])\n",
    "print(\"mixing_probabilities: \", mixing_probabilities.shape)\n",
    "loc = jnp.vstack([jnp.zeros(k) / k for _ in range(s)])\n",
    "print(\"loc: \", loc.shape)\n",
    "scale =jnp.vstack([jnp.ones(k) / k for _ in range(s)])\n",
    "print(\"scale: \", scale.shape)\n",
    "print('')\n",
    "normal= dist.Normal(loc=loc, scale=scale)\n",
    "print(\"normal.shape(): \", normal.shape())\n",
    "print(\"normal.batch_shape: \", normal.batch_shape)\n",
    "print(\"normal.event_shape: \", normal.event_shape)\n",
    "print(\"normal.event_dim: \", normal.event_dim)\n",
    "print('')\n",
    "mixed = MixtureSameFamily(mixing_probabilities=mixing_probabilities, component_distribution=normal)\n",
    "print(\"mixed.shape(): \", mixed.shape())\n",
    "print(\"mixed.batch_shape: \", mixed.batch_shape)\n",
    "print(\"mixed.event_shape: \", mixed.event_shape)\n",
    "print(\"mixed.event_dim: \", mixed.event_dim)\n",
    "print('')\n",
    "samples = mixed.sample(rng_key, (100,))\n",
    "print('samples: ', samples.shape)\n",
    "print('')\n",
    "lp = mixed.log_prob(samples)\n",
    "print('lp: ', lp.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a82c6b7-4e46-4eca-9fd0-4920226a2148",
   "metadata": {},
   "outputs": [],
   "source": [
    "jnp.vstack([jnp.ones(k) / k for _ in range(1)]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe7f361f-48eb-4726-8f4b-7be9ec7dfa7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 3\n",
    "d = 2\n",
    "mixing_probabilities = jnp.ones(k) / k\n",
    "print(\"mixing_probabilities: \", mixing_probabilities.shape)\n",
    "loc = jnp.zeros((k, d))\n",
    "print(\"loc: \", loc.shape)\n",
    "cov_matrix = jnp.repeat(jnp.expand_dims(jnp.eye(d, d), 0), k, axis=0)\n",
    "print(\"cov_matrix: \", cov_matrix.shape)\n",
    "print('')\n",
    "normal= dist.MultivariateNormal(loc=loc, covariance_matrix=cov_matrix)\n",
    "print(\"normal.shape(): \", normal.shape())\n",
    "print(\"normal.batch_shape: \", normal.batch_shape)\n",
    "print(\"normal.event_shape: \", normal.event_shape)\n",
    "print(\"normal.event_dim: \", normal.event_dim)\n",
    "print('')\n",
    "mixed = MixtureSameFamily(mixing_probabilities=mixing_probabilities, component_distribution=normal)\n",
    "print(\"mixed.shape(): \", mixed.shape())\n",
    "print(\"mixed.batch_shape: \", mixed.batch_shape)\n",
    "print(\"mixed.event_shape: \", mixed.event_shape)\n",
    "print(\"mixed.event_dim: \", mixed.event_dim)\n",
    "print('')\n",
    "samples = mixed.sample(rng_key, (100,))\n",
    "print('samples: ', samples.shape)\n",
    "print('')\n",
    "lp = mixed.log_prob(samples)\n",
    "print('lp: ', lp.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "802b202d-d981-42dc-86ac-87381f898089",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 3\n",
    "d = 1\n",
    "mixing_probabilities = jnp.ones(k) / k\n",
    "print(\"mixing_probabilities: \", mixing_probabilities.shape)\n",
    "loc = jnp.zeros((k, d))\n",
    "print(\"loc: \", loc.shape)\n",
    "cov_matrix = jnp.repeat(jnp.expand_dims(jnp.eye(d, d), 0), k, axis=0)\n",
    "print(\"cov_matrix: \", cov_matrix.shape)\n",
    "print('')\n",
    "normal= dist.MultivariateNormal(loc=loc, covariance_matrix=cov_matrix)\n",
    "print(\"normal.shape(): \", normal.shape())\n",
    "print(\"normal.batch_shape: \", normal.batch_shape)\n",
    "print(\"normal.event_shape: \", normal.event_shape)\n",
    "print(\"normal.event_dim: \", normal.event_dim)\n",
    "print('')\n",
    "mixed = MixtureSameFamily(mixing_probabilities=mixing_probabilities, component_distribution=normal)\n",
    "print(\"mixed.shape(): \", mixed.shape())\n",
    "print(\"mixed.batch_shape: \", mixed.batch_shape)\n",
    "print(\"mixed.event_shape: \", mixed.event_shape)\n",
    "print(\"mixed.event_dim: \", mixed.event_dim)\n",
    "print('')\n",
    "samples = mixed.sample(rng_key, (100,))\n",
    "print('samples: ', samples.shape)\n",
    "print('')\n",
    "lp = mixed.log_prob(samples)\n",
    "print('lp: ', lp.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c06503f8-1eb2-4e2f-b1eb-bf84c3d20458",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 3\n",
    "d = 2\n",
    "mixing_probabilities = jnp.ones(k) / k\n",
    "print(\"mixing_probabilities: \", mixing_probabilities.shape)\n",
    "loc = jnp.zeros((k, d))\n",
    "print(\"loc: \", loc.shape)\n",
    "cov_matrix = jnp.repeat(jnp.expand_dims(jnp.eye(d, d), 0), k, axis=0)\n",
    "print(\"cov_matrix: \", cov_matrix.shape)\n",
    "print('')\n",
    "normal= dist.MultivariateNormal(loc=loc, covariance_matrix=cov_matrix)\n",
    "print(\"normal.shape(): \", normal.shape())\n",
    "print(\"normal.batch_shape: \", normal.batch_shape)\n",
    "print(\"normal.event_shape: \", normal.event_shape)\n",
    "print(\"normal.event_dim: \", normal.event_dim)\n",
    "print('')\n",
    "mixed = MixtureSameFamily(mixing_probabilities=mixing_probabilities, component_distribution=normal)\n",
    "print(\"mixed.shape(): \", mixed.shape())\n",
    "print(\"mixed.batch_shape: \", mixed.batch_shape)\n",
    "print(\"mixed.event_shape: \", mixed.event_shape)\n",
    "print(\"mixed.event_dim: \", mixed.event_dim)\n",
    "print('')\n",
    "samples = mixed.sample(rng_key, (100, 7))\n",
    "print('samples: ', samples.shape)\n",
    "print('')\n",
    "lp = mixed.log_prob(samples)\n",
    "print('lp: ', lp.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed6d983d-7488-445f-a35a-a17a501394e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "mixed._component_distribution.tree_flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "744567e3-a40f-430e-9581-4306c68ffe96",
   "metadata": {},
   "source": [
    "## Try GMM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f57d947-5cb2-4c14-b355-ec613754d379",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "n = 2500 # Total number of samples\n",
    "k = 3  # Number of clusters\n",
    "p_real = np.array([0.2, 0.3, 0.5])  # Probability of choosing each cluster\n",
    "mus_real = np.array([-1., 1., 4.])  #  Mu of clusters\n",
    "sigmas_real = np.array([0.2, 0.9, 0.5])  # Sigma of clusters\n",
    "clusters = np.random.choice(k, size=n, p=p_real)\n",
    "x_data = np.random.normal(mus_real[clusters], sigmas_real[clusters], size=n)\n",
    "\n",
    "print(f'{n} samples in total from {k} clusters. x_data: {x_data.shape}')\n",
    "fig, ax = plt.subplots(1, 1, figsize=(6, 3))\n",
    "sns.histplot(x_data, kde=True, ax=ax)\n",
    "ax.set_xlabel('x')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f614539-91f2-477e-8780-5df6984e26d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gmm_model(k, x=None):\n",
    "    # Prior for cluster probabilities\n",
    "    prob_cluster = numpyro.sample('prob_cluster', dist.Dirichlet(concentration=jnp.ones(k)))\n",
    "    print(\"prob_cluster: \", prob_cluster.shape)\n",
    "    # Prior on cluster means\n",
    "    with numpyro.plate('k_plate', k):\n",
    "        loc = numpyro.sample('loc', dist.Normal(loc=0., scale=10.))\n",
    "        scale = numpyro.sample('scale', dist.HalfCauchy(scale=10))\n",
    "    print(\"loc: \", loc.shape)\n",
    "    print(\"scale: \", scale.shape)\n",
    "    normal= dist.Normal(loc=loc, scale=scale)\n",
    "    print(\"normal.shape(): \", normal.shape())\n",
    "    mixed = MixtureSameFamily(mixing_probabilities=prob_cluster, component_distribution=normal)\n",
    "    print(\"mixed.shape(): \", mixed.shape())\n",
    "    print(\"mixed.batch_shape: \", mixed.batch_shape)\n",
    "    print(\"mixed.event_shape: \", mixed.event_shape)\n",
    "    print(\"mixed.event_dim: \", mixed.event_dim)\n",
    "    mixed = numpyro.sample('x', mixed, obs=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12d058b4-2905-4b72-8f1b-910f4b5d7cdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "rng_key = jax.random.PRNGKey(42)\n",
    "\n",
    "num_warmup, num_samples = 1000, 2000\n",
    "\n",
    "# Run NUTS.\n",
    "kernel = NUTS(gmm_model)\n",
    "mcmc = MCMC(\n",
    "    kernel,\n",
    "    num_warmup=num_warmup,\n",
    "    num_samples=num_samples,\n",
    ")\n",
    "mcmc.run(rng_key, x=x_data, k=k)\n",
    "mcmc.print_summary()\n",
    "posterior_samples = mcmc.get_samples()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e187efd-7665-4cac-9af3-ffa6060a5c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%debug"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
