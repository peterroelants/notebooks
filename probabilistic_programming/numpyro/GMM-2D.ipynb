{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0c2ee2c6-fc16-4238-8f13-73ed06e5b8d7",
   "metadata": {},
   "source": [
    "# 2D GMM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "145f43b6-3cc4-4f05-904e-c83f38cf9c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'svg'\n",
    "\n",
    "import sys\n",
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "\n",
    "import numpyro\n",
    "from numpyro.infer import MCMC, NUTS, Predictive\n",
    "import numpyro.distributions as dist\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm  # Colormaps\n",
    "import seaborn as sns\n",
    "import arviz as az\n",
    "\n",
    "from tqdm import tqdm_notebook as tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1320bdd-1638-4184-8574-09c6f14bb59f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style('darkgrid')\n",
    "az.rcParams['stats.hdi_prob'] = 0.90\n",
    "az.style.use(\"arviz-darkgrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba441224-0333-4fd7-b470-e6d8f9a9f222",
   "metadata": {},
   "outputs": [],
   "source": [
    "numpyro.set_platform('cpu')\n",
    "numpyro.set_host_device_count(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fa67e43-22a8-40a1-a67b-638419f826f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "rng_key = jax.random.PRNGKey(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c0309c7-9e19-4fc4-b02c-485225f582aa",
   "metadata": {},
   "source": [
    "## Create data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4235e94b-66e5-4bf9-b056-194e27883af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "n = 1000 # Total number of samples\n",
    "k = 3  # Number of clusters\n",
    "p_real = np.array([0.2, 0.5, 0.3])  # Probability of choosing each cluster\n",
    "assert np.isclose(p_real.sum(), 1.)\n",
    "print(\"p_real: \", p_real.shape)\n",
    "loc_real = np.array([  # Mean of clusters\n",
    "    [-1.2, 1.5],\n",
    "    [2., 2.],\n",
    "    [-1, 4.]\n",
    "])\n",
    "assert loc_real.shape == (3, 2)\n",
    "print(\"loc_real: \", loc_real.shape)\n",
    "cov_real = np.array([\n",
    "    [\n",
    "        [0.1, -0.2],\n",
    "        [-0.2, 1.0],\n",
    "    ],\n",
    "    [\n",
    "        [0.75, 0.0],\n",
    "        [0.0, 0.75],\n",
    "    ],\n",
    "    [\n",
    "        [1.0, 0.5],\n",
    "        [0.5, 0.27],\n",
    "    ],\n",
    "])  # Covariance of clusters\n",
    "assert cov_real.shape == (3, 2, 2)\n",
    "print(\"cov_real: \", cov_real.shape)\n",
    "for i in range(k):\n",
    "    assert (np.linalg.eigvals(cov_real[i]) > 0).all()\n",
    "    assert np.allclose(cov_real[i], cov_real[i].T)\n",
    "L_real = np.stack([\n",
    "    np.linalg.cholesky(cov_real[i])\n",
    "    for i in range(k)\n",
    "])\n",
    "print(\"L_real: \", L_real.shape)\n",
    "\n",
    "\n",
    "nb_cluster_samples = (n * p_real).astype(np.int32)\n",
    "assert len(nb_cluster_samples) == k\n",
    "nb_cluster_samples[-1] = n - nb_cluster_samples[:-1].sum()\n",
    "assert nb_cluster_samples.sum() == n\n",
    "\n",
    "clusters = np.hstack([\n",
    "    np.ones(nbcs, dtype=np.int32) * idx for idx, nbcs in enumerate(nb_cluster_samples)\n",
    "])\n",
    "assert clusters.shape[0] == n, clusters.shape\n",
    "assert (np.unique(clusters, return_counts=True)[-1] == nb_cluster_samples).all()\n",
    "\n",
    "obs_data = np.vstack([\n",
    "    np.random.multivariate_normal(loc_real[idx], cov_real[idx], size=nbcs)\n",
    "    for idx, nbcs in enumerate(nb_cluster_samples)\n",
    "])\n",
    "assert obs_data.shape == (n, 2)\n",
    "\n",
    "# Shuffle\n",
    "_idx_permutations = np.random.permutation(n)\n",
    "clusters = clusters[_idx_permutations]\n",
    "obs_data = obs_data[_idx_permutations, :]\n",
    "\n",
    "cmap = {\n",
    "    i: sns.color_palette(\"tab10\")[i]\n",
    "    for i in range(k)\n",
    "}\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(7, 5))\n",
    "for i in range(k):\n",
    "    c_idx = (clusters == i)\n",
    "    ax.plot(obs_data[c_idx, 0], obs_data[c_idx, 1], 'o', alpha=0.3, color=cmap[i], label=i)\n",
    "ax.set_xlim(-5, 5)\n",
    "ax.set_ylim(-2, 6)\n",
    "ax.set_aspect('equal')\n",
    "ax.set_title('Observations')\n",
    "ax.set_xlabel('x')\n",
    "ax.set_ylabel('y')\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49f1fc14-1d61-411d-8957-cdfbbe8932b8",
   "metadata": {},
   "source": [
    "## Test NumPyro Multivariate distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e3b7fe8-66a2-43b9-b07c-f3ac84c056ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "_mvn = dist.MultivariateNormal(loc=loc_real[2], covariance_matrix=cov_real[2])\n",
    "_mvn_samples = _mvn.sample(rng_key, (100,))\n",
    "print(_mvn_samples.shape)\n",
    "fig, ax = plt.subplots(1, 1, figsize=(7, 5))\n",
    "ax.plot(_mvn_samples[:, 0], _mvn_samples[:, 1], 'o', alpha=0.3, color=cmap[2], label=2)\n",
    "ax.set_xlim(-5, 5)\n",
    "ax.set_ylim(-2, 6)\n",
    "ax.set_aspect('equal')\n",
    "ax.set_title('Test MultivariateNormal')\n",
    "ax.set_xlabel('x')\n",
    "ax.set_ylabel('y')\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "250f0605-cc5f-4f78-a00a-dbef597041ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"loc_real: \", loc_real.shape)\n",
    "print(\"cov_real: \", cov_real.shape)\n",
    "print(\"p_real: \", p_real.shape)\n",
    "\n",
    "_mvn_multi = dist.MultivariateNormal(loc=loc_real, covariance_matrix=cov_real)\n",
    "print(\"_mvn_multi.shape(): \", _mvn_multi.shape())\n",
    "print(\"_mvn_multi.batch_shape: \", _mvn_multi.batch_shape)\n",
    "print(\"_mvn_multi.event_shape: \", _mvn_multi.event_shape)\n",
    "print(\"_mvn_multi.event_dim: \", _mvn_multi.event_dim)\n",
    "_mvn_multi_samples = _mvn_multi.sample(rng_key, (1000,))\n",
    "print(\"_mvn_multi_samples: \", _mvn_multi_samples.shape)\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(7, 5))\n",
    "for i in range(k):\n",
    "    ax.plot(_mvn_multi_samples[:, i, 0], _mvn_multi_samples[:, i, 1], 'o', alpha=0.3, color=cmap[i], label=i)\n",
    "ax.set_xlim(-5, 5)\n",
    "ax.set_ylim(-2, 6)\n",
    "ax.set_aspect('equal')\n",
    "ax.set_title('Test MultivariateNormal multiple distributions')\n",
    "ax.set_xlabel('x')\n",
    "ax.set_ylabel('y')\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fefc1cda-0cb0-4e76-a3f6-0e6e8a0b14ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# _p_real = np.array([0.2, 0.5, 0.3])  # Probability of choosing each cluster\n",
    "# assert np.isclose(_p_real.sum(), 1.)\n",
    "# print(\"_p_real: \", _p_real.shape)\n",
    "# _loc_real = np.array([\n",
    "#     [-1.2, 2., -1],\n",
    "#     [1.5, 2., 4.]\n",
    "# ])\n",
    "# assert _loc_real.shape == (2, 3)\n",
    "# print(\"_loc_real: \", _loc_real.shape)\n",
    "# _cov_real = np.array([\n",
    "#     [\n",
    "#         [0.1, 0.75, 1.0],\n",
    "#         [-0.2, 0.0, 0.5],\n",
    "#     ],\n",
    "#     [\n",
    "#         [-0.2, 0.0, 0.5],\n",
    "#         [1.0, 0.75, 0.27],\n",
    "#     ],\n",
    "# ])\n",
    "# assert _cov_real.shape == (2, 2, 3)\n",
    "# print(\"_cov_real: \", _cov_real.shape)\n",
    "# print(\"_loc_real: \", _loc_real.shape)\n",
    "# print(\"_cov_real: \", _cov_real.shape)\n",
    "# print(\"_p_real: \", _p_real.shape)\n",
    "\n",
    "# _mvn_multi = dist.MultivariateNormal(loc=_loc_real, covariance_matrix=_cov_real)\n",
    "# print(\"_mvn_multi.shape(): \", _mvn_multi.shape())\n",
    "# print(\"_mvn_multi.batch_shape: \", _mvn_multi.batch_shape)\n",
    "# print(\"_mvn_multi.event_shape: \", _mvn_multi.event_shape)\n",
    "# print(\"_mvn_multi.event_dim: \", _mvn_multi.event_dim)\n",
    "# _mvn_multi_samples = _mvn_multi.sample(rng_key, (1000,))\n",
    "# print(\"_mvn_multi_samples: \", _mvn_multi_samples.shape)\n",
    "\n",
    "# # fig, ax = plt.subplots(1, 1, figsize=(7, 5))\n",
    "# # for i in range(k):\n",
    "# #     ax.plot(_mvn_multi_samples[:, i, 0], _mvn_multi_samples[:, i, 1], 'o', alpha=0.3, color=cmap[i], label=i)\n",
    "# # ax.set_xlim(-5, 5)\n",
    "# # ax.set_ylim(-2, 6)\n",
    "# # ax.set_aspect('equal')\n",
    "# # ax.set_title('Test MultivariateNormal multiple distributions')\n",
    "# # ax.set_xlabel('x')\n",
    "# # ax.set_ylabel('y')\n",
    "# # ax.legend()\n",
    "# # plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72349f53-af06-42d4-bd77-77a9036f8c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "_cat = dist.Categorical(p_real, validate_args=True)\n",
    "_cat_samples = _cat.sample(rng_key, (100,))\n",
    "print(_cat_samples.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "233a272d-a182-4635-9633-dc8238111647",
   "metadata": {},
   "source": [
    "## Mixture distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7098f456-a932-4d87-8e16-0cc9abeb0b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MixtureMultivariateNormal(dist.Distribution):\n",
    "    def __init__(self, mixing_probs, loc, covariance_matrix=None, scale_tril=None, validate_args=False):\n",
    "        print(\"loc: \", loc.shape)\n",
    "        print(\"mixing_probs: \", mixing_probs.shape)\n",
    "        if covariance_matrix is not None and scale_tril is not None:\n",
    "            raise AttributeError(\"Only one of `covariance_matrix` or `scale_tril` can be given\")\n",
    "        if covariance_matrix is None and scale_tril is None:\n",
    "            raise AttributeError(\"One of `covariance_matrix` or `scale_tril` needs to be given\")\n",
    "        if covariance_matrix is not None:\n",
    "            print(\"covariance_matrix: \", covariance_matrix.shape)\n",
    "            self._mvn = dist.MultivariateNormal(loc=loc, covariance_matrix=covariance_matrix, validate_args=validate_args)\n",
    "        if scale_tril is not None:\n",
    "            print(\"scale_tril: \", scale_tril.shape)\n",
    "            self._mvn = dist.MultivariateNormal(loc=loc, scale_tril=scale_tril, validate_args=validate_args)\n",
    "        self._categorical = dist.Categorical(mixing_probs, validate_args=validate_args)\n",
    "        super().__init__(validate_args=validate_args)\n",
    "\n",
    "    def sample(self, key, sample_shape=()):\n",
    "        print(f\"sample(sample_shape={sample_shape})\")\n",
    "        key, key_idx = jax.random.split(key)\n",
    "        samples = self._mvn.sample(key, sample_shape)\n",
    "        print(f\"samples={samples.shape})\")\n",
    "        ind = self._categorical.sample(key_idx, sample_shape)\n",
    "        print(f\"ind={ind.shape})\")\n",
    "        print(f\"ind[..., None, None]={ind[..., None, None].shape})\")\n",
    "        return jnp.take_along_axis(samples, ind[..., None, None], 1)[:, 0, :]\n",
    "\n",
    "    def log_prob(self, value):\n",
    "        print(f\"log_prob(value={value.shape})\")\n",
    "        print(f\"value[:, None, :]: {value[:, None, :].shape}\")\n",
    "        probs_mixture = self._mvn.log_prob(value[:, None, :])\n",
    "        print(\"probs_mixture: \", probs_mixture.shape)\n",
    "        print(\"self._categorical.logits: \", self._categorical.logits.shape)\n",
    "        sum_probs = self._categorical.logits + probs_mixture\n",
    "        print(\"sum_probs: \", sum_probs.shape)\n",
    "        lse = jax.nn.logsumexp(sum_probs, axis=-1)\n",
    "        print(\"lse: \", lse.shape)\n",
    "        return lse\n",
    "\n",
    "    \n",
    "_mvn_mixture = MixtureMultivariateNormal(loc=loc_real, covariance_matrix=cov_real, mixing_probs=p_real, validate_args=True)\n",
    "_mvn_mixture_samples = _mvn_mixture.sample(rng_key, (1000,))\n",
    "print(\"_mvn_mixture_samples: \", _mvn_mixture_samples.shape)\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(7, 5))\n",
    "ax.plot(_mvn_mixture_samples[:, 0], _mvn_mixture_samples[:, 1], 'o', alpha=0.3)\n",
    "ax.set_xlim(-5, 5)\n",
    "ax.set_ylim(-2, 6)\n",
    "ax.set_aspect('equal')\n",
    "ax.set_title('Observations')\n",
    "ax.set_xlabel('x')\n",
    "ax.set_ylabel('y')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "_lp = _mvn_mixture.log_prob(_mvn_mixture_samples)\n",
    "print(\"_lp: \", _lp.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b61e3df-e08d-47dc-a298-917a5e86f466",
   "metadata": {},
   "source": [
    "### Gaussian Mixture Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d788b85-5f9e-460e-b63a-9f8c082c5e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gmm_model(d, k, obs=None):\n",
    "    # Prior for cluster probabilities\n",
    "    prob_cluster = numpyro.sample('prob_cluster', dist.Dirichlet(concentration=jnp.ones((k, ))))\n",
    "    print(\"prob_cluster: \", prob_cluster.shape)\n",
    "    # Prior on cluster means\n",
    "    with numpyro.plate('k_plate', k, dim=-2):\n",
    "        scale = numpyro.sample(\"scale\", dist.HalfCauchy(scale=jnp.ones(d)*2))\n",
    "        print(\"scale: \", scale.shape)\n",
    "        loc = numpyro.sample('loc', dist.Cauchy(loc=jnp.zeros(d), scale=jnp.ones(d)*2))\n",
    "        print(\"loc: \", loc.shape)\n",
    "    with numpyro.plate('k_plate', k, dim=-1):\n",
    "        lkj_chol = numpyro.sample(\"lkj_chol\", dist.LKJCholesky(dimension=d, concentration=1.))\n",
    "        print(\"lkj_chol: \", lkj_chol.shape)\n",
    "        L_cov = numpyro.deterministic(\"L_cov\", scale[..., None] * lkj_chol)\n",
    "        print(\"L_cov: \", L_cov.shape)\n",
    "    numpyro.sample('obs', MixtureMultivariateNormal(mixing_probs=prob_cluster, loc=loc, scale_tril=L_cov), obs=obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b792b24f-83fc-40c1-9f41-97d411d1376b",
   "metadata": {},
   "outputs": [],
   "source": [
    "rng_key = jax.random.PRNGKey(42)\n",
    "\n",
    "num_warmup, num_samples = 1000, 2000\n",
    "\n",
    "# Run NUTS.\n",
    "kernel = NUTS(gmm_model)\n",
    "mcmc = MCMC(\n",
    "    kernel,\n",
    "    num_warmup=num_warmup,\n",
    "    num_samples=num_samples,\n",
    "    num_chains=4,\n",
    "    chain_method='parallel',\n",
    ")\n",
    "mcmc.run(rng_key, d=2, k=3, obs=obs_data)\n",
    "mcmc.print_summary()\n",
    "posterior_samples = mcmc.get_samples()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2516ac0-8d52-484a-9dd3-ed46bc89df6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore', message=\"divide by zero encountered in true_divide\")\n",
    "warnings.filterwarnings('ignore', message=\"invalid value encountered in true_divide\")\n",
    "warnings.filterwarnings('ignore', message=\"invalid value encountered in double_scalars\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0152a709-112a-4f96-b798-d17cdb2510ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "az.summary(mcmc, var_names=[\"~lkj_chol\", \"~L_cov\", \"~scale\"], round_to=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e9e4a84-5ac8-4d5f-8a8e-436f13e8579c",
   "metadata": {},
   "outputs": [],
   "source": [
    "rng_key = jax.random.PRNGKey(42)\n",
    "\n",
    "posterior_predictive = Predictive(gmm_model, posterior_samples=posterior_samples, batch_ndims=0)\n",
    "posterior_predictions = posterior_predictive(rng_key, d=2, k=3, obs=None)\n",
    "print('Posterior predictions: ', posterior_predictions['obs'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45bdb5ad-87cb-431c-9fba-e7d2c3543a02",
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_data = az.from_numpyro(\n",
    "    posterior=mcmc,\n",
    "    posterior_predictive=posterior_predictions,\n",
    "    coords={\"cluster\": np.arange(k), \"dim\": np.arange(2)},\n",
    "    dims={\"loc\": [\"cluster\", \"dim\"], \"scale\": [\"cluster\", \"dim\"], \"prob_cluster\": [\"cluster\"]}\n",
    ")\n",
    "display(inference_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95d661e8-0fa9-48e6-b0f5-16d94bfb3ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "az.plot_trace(\n",
    "    inference_data,\n",
    "    compact=True,\n",
    "    var_names=[\"~lkj_chol\"],\n",
    "    lines=[\n",
    "        (\"prob_cluster\", {}, p_real),\n",
    "        (\"loc\", {}, loc_real),\n",
    "        (\"L_cov\", {}, L_real)\n",
    "    ],\n",
    ")\n",
    "plt.suptitle('Trace plots', fontsize=18)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa740ca7-5a92-40c4-8436-41ba030752cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(7, 5))\n",
    "ax.plot(posterior_predictions[\"obs\"][:, 0], posterior_predictions[\"obs\"][:, 1], 'o', alpha=0.1)\n",
    "ax.set_xlim(-5, 5)\n",
    "ax.set_ylim(-2, 6)\n",
    "ax.set_aspect('equal')\n",
    "ax.set_title('Posterior predicted observations')\n",
    "ax.set_xlabel('x')\n",
    "ax.set_ylabel('y')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
